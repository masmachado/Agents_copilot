```instructions
---
applyTo: "**/*.yml,**/*.yaml"
---

# Regras para Arquivos YAML (.yml/.yaml) ‚Äì Pipelines e Jobs Databricks

## Contexto

Este reposit√≥rio cont√©m pipelines de dados no **Databricks** usando:

| Tecnologia | Descri√ß√£o |
|------------|-----------|
| **DLT (Delta Live Tables)** | Framework declarativo para pipelines de dados com qualidade integrada |
| **DABs (Databricks Asset Bundles)** | Empacotamento de recursos YAML para deploy entre ambientes |
| **Unity Catalog** | Governan√ßa centralizada de dados (cat√°logos, schemas, tabelas) |

**Ambientes de deploy:** `dev` ‚Üí `hml` (homologa√ß√£o) ‚Üí `prd` (produ√ß√£o)

**Camadas de dados:** `bronze` (raw) ‚Üí `trusted` (limpo/validado) ‚Üí `refined` (modelado/agregado)

**Cat√°logos por camada:**
- `catalog_raw` - dados brutos (bronze)
- `catalog_trusted` - dados limpos/validados
- `catalog_refined` - dados modelados/agregados
- `catalog_stg` - staging

**Localiza√ß√£o dos arquivos:**
- Pipelines DLT: `resources/dlt_<processo>.pipeline.yml`
- Jobs: `resources/job_<processo>.job.yml`
- Notebooks DLT: `src/dlt/<trusted|refined>/<pasta>/<arquivo>.ipynb`

---

## Classifica√ß√£o de Severidade e A√ß√£o do Revisor

| Severidade | Crit√©rio | A√ß√£o |
|------------|----------|------|
| üî¥ **BLOCKER** | Segredo exposto, credencial em texto claro | **REJEITAR PR** imediatamente, solicitar remo√ß√£o do hist√≥rico git |
| üü† **CRITICAL** | Path absoluto, cat√°logo hardcoded, YAML inv√°lido | **REQUEST CHANGES** com corre√ß√£o obrigat√≥ria antes do merge |
| üü° **MAJOR** | Falta timeout, falta webhook, nomenclatura fora do padr√£o | **REQUEST CHANGES** com sugest√£o de corre√ß√£o |
| üü¢ **MINOR** | Indenta√ß√£o inconsistente, coment√°rio ausente, ordem de chaves | **COMMENT** como sugest√£o de melhoria |

---

## Padr√µes de Viola√ß√£o a Detectar

### üî¥ BLOCKER: Seguran√ßa (rejeitar imediatamente)

Detectar e **REJEITAR** qualquer arquivo contendo:

| Padr√£o | Exemplo de Viola√ß√£o |
|--------|---------------------|
| Segredo em texto claro | `password: minhasenha123` |
| Token exposto | `token: ghp_xxxxxxxxxxxx` ou `token: dapi123456789` |
| Chave de API literal | `api_key: "sk-xxxxxxxx"` |
| Credencial AWS/Azure | `aws_access_key_id: AKIA...` |

**Regra:** Qualquer valor ap√≥s `password:`, `secret:`, `token:`, `api_key:`, `access_key:` que N√ÉO seja uma vari√°vel `${...}` √© uma viola√ß√£o BLOCKER.

---

### üü† CRITICAL: Hardcoding (solicitar corre√ß√£o obrigat√≥ria)

#### Cat√°logo Hardcoded

‚ùå **Proibido:**
```yaml
catalog: dev_lake
catalog: hml_lake  
catalog: prd_lake
catalog: trusted
catalog: refined
```

‚úÖ **Obrigat√≥rio:**
```yaml
catalog: ${var.catalog_<camada>}
```

Onde `<camada>` √©: `raw`, `trusted`, `refined` ou `stg`.

**Exemplos corretos:**
```yaml
catalog: ${var.catalog_raw}
catalog: ${var.catalog_trusted}
catalog: ${var.catalog_refined}
catalog: ${var.catalog_stg}
```

**Regra:** O campo `catalog:` DEVE usar `${var.catalog_<camada>}`. Valores literais contendo `dev_`, `hml_`, `stg_`, `prd_`, `trusted`, `refined`, `bronze` s√£o viola√ß√µes CRITICAL.

---

#### Schema Hardcoded

‚ùå **Proibido:**
```yaml
schema: bronze
schema: trusted_vendas
```

‚úÖ **Obrigat√≥rio:**
```yaml
schema: ${var.schema}
```

**Regra:** O campo `schema:` DEVE usar vari√°vel `${var.schema}` ou `${var.schema_name}`. Valores literais s√£o viola√ß√µes CRITICAL.

---

#### Path Absoluto

‚ùå **Proibido:**
```yaml
notebook_path: /Workspace/Users/usuario@sabesp.com.br/projeto/notebook
notebook_path: /Repos/projeto/src/notebooks/processo
path: /dbfs/mnt/dados/arquivo.csv
```

‚úÖ **Obrigat√≥rio:**
```yaml
path: ../src/dlt/trusted/<pasta>/<arquivo>.ipynb
path: ../src/dlt/refined/<pasta>/<arquivo>.ipynb
```

**Regra:** Paths DEVEM come√ßar com `./`, `../` ou usar vari√°veis `${var.xxx}`. Qualquer path iniciando com `/Workspace`, `/Repos`, `/Users`, `/dbfs`, `/mnt` √© viola√ß√£o CRITICAL.

**Padr√£o de path para notebooks DLT:**
```
../src/dlt/<camada>/<pasta>/<arquivo>.ipynb
```

---

### üü° MAJOR: Estrutura Incompleta

#### Job sem Schedule

**Regra:** Todo arquivo `*.job.yml` DEVE conter bloco `schedule:` com `quartz_cron_expression` v√°lido.

‚ùå **Viola√ß√£o:** Arquivo job sem bloco schedule
‚úÖ **Corre√ß√£o:** Adicionar schedule apropriado

---

#### Job sem Notifica√ß√£o

**Regra:** Todo job DEVE ter `webhook_notifications:` OU `email_notifications:` configurado para falhas.

‚ùå **Viola√ß√£o:** Job sem nenhum bloco de notifica√ß√£o
‚úÖ **Corre√ß√£o:** Adicionar `webhook_notifications.on_failure` ou `email_notifications.on_failure`

---

#### Task sem Timeout

**Regra:** Toda `notebook_task:` ou `python_wheel_task:` DEVE ter `timeout_seconds:` definido.

‚ùå **Viola√ß√£o:**
```yaml
notebook_task:
  notebook_path: ./notebooks/processo
```

‚úÖ **Corre√ß√£o:**
```yaml
notebook_task:
  notebook_path: ./notebooks/processo
timeout_seconds: 3600
```

---

#### Nomenclatura Fora do Padr√£o

**Regras de nomenclatura:**
- Pipelines: `resources/dlt_<processo>.pipeline.yml`
- Jobs: `resources/job_<processo>.job.yml`

‚ùå **Viola√ß√£o:** `resources/meu_pipeline.yml`, `resources/job-vendas.yml`
‚úÖ **Corre√ß√£o:** `resources/dlt_vendas.pipeline.yml`, `resources/job_vendas.job.yml`

---

#### Pipeline trusted/refined sem DLT

**Regra:** Pipelines que processam camadas `trusted` ou `refined` DEVEM usar DLT (Delta Live Tables).

‚ùå **Viola√ß√£o:** Job com notebook processando trusted/refined diretamente
‚úÖ **Corre√ß√£o:** Migrar para pipeline DLT em `src/dlt/<camada>/`

---

## Estrutura Obrigat√≥ria

### Template de Job

Todo arquivo `*.job.yml` DEVE seguir esta estrutura:

```yaml
resources:
  jobs:
    <nome_job>:
      name: <nome_job>
      
      # OBRIGAT√ìRIO: Agendamento
      schedule:
        quartz_cron_expression: "<cron>"
        timezone_id: UTC
        pause_status: UNPAUSED  # ou PAUSED
      
      # OBRIGAT√ìRIO: Pelo menos uma task
      tasks:
        - task_key: <nome_task>
          pipeline_task:
            pipeline_id: ${resources.pipelines.pipeline_<nome_pipeline>.id}
            full_refresh: false
      
      # OBRIGAT√ìRIO: Notifica√ß√£o de falha
      webhook_notifications:
        on_failure:
          - id: ${var.webhook_id}
      
      # OBRIGAT√ìRIO: Fila de execu√ß√£o
      queue:
        enabled: true
      
      # RECOMENDADO: Otimiza√ß√£o de performance
      performance_target: PERFORMANCE_OPTIMIZED
      
      # OBRIGAT√ìRIO: Permiss√µes
      permissions:
        - group_name: "grp_engenharia_dados_db_basico"
          level: "CAN_MANAGE_RUN"
```

**Campos OBRIGAT√ìRIOS (aus√™ncia = MAJOR):**
- `schedule` com `quartz_cron_expression`, `timezone_id: UTC` e `pause_status`
- `tasks` com pelo menos uma task
- `pipeline_task` com `pipeline_id` referenciando o pipeline via `${resources.pipelines.pipeline_<nome>.id}`
- `full_refresh: false` (ou `true` quando necess√°rio)
- `webhook_notifications` com `on_failure` usando `${var.webhook_id}`
- `queue` com `enabled: true`
- `permissions` com grupo `grp_engenharia_dados_db_basico` e level `CAN_MANAGE_RUN`

---

### Template de Pipeline DLT

Todo arquivo `*.pipeline.yml` DEVE seguir esta estrutura:

```yaml
resources:
  pipelines:
    <nome_pipeline>:
      name: <nome_pipeline>
      
      # OBRIGAT√ìRIO: Bibliotecas/notebooks
      libraries:
        - notebook:
            path: ../src/dlt/<camada>/<pasta>/<arquivo>.ipynb
      
      # OBRIGAT√ìRIO: Schema alvo
      schema: <schema>
      
      # OBRIGAT√ìRIO: Cat√°logo via vari√°vel por camada
      catalog: ${var.catalog_<camada>}
      
      # OBRIGAT√ìRIO: Configura√ß√µes de execu√ß√£o
      photon: true  # ou false
      serverless: true  # ou false
      allow_duplicate_names: true  # ou false
      
      # OBRIGAT√ìRIO: Permiss√µes
      permissions:
        - group_name: "grp_engenharia_dados_db_basico"
          level: "CAN_MANAGE"
```

**Campos OBRIGAT√ìRIOS (aus√™ncia = MAJOR):**
- `name` com nome do pipeline
- `libraries` com notebook usando path relativo `../src/dlt/<camada>/...`
- `schema` definindo o schema alvo
- `catalog` usando vari√°vel `${var.catalog_<camada>}` (raw, trusted, refined, stg)
- `photon` definido (true/false)
- `serverless` definido (true/false)
- `allow_duplicate_names` definido (true/false)
- `permissions` com grupo `grp_engenharia_dados_db_basico`

---

## Exemplos de Coment√°rios de Review

### Para cat√°logo hardcoded:

> üü† **CRITICAL: Cat√°logo hardcoded detectado**
> 
> **Linha:** `catalog: dev_lake`
> 
> **Problema:** Cat√°logos hardcoded impedem deploy autom√°tico entre ambientes.
> 
> **Corre√ß√£o obrigat√≥ria:**
> ```yaml
> catalog: ${var.catalog_trusted}
> ```
> 
> Use a vari√°vel correspondente √† camada: `${var.catalog_raw}`, `${var.catalog_trusted}`, `${var.catalog_refined}` ou `${var.catalog_stg}`.

---

### Para path absoluto:

> üü† **CRITICAL: Path absoluto n√£o permitido**
> 
> **Linha:** `path: /Workspace/Users/usuario@sabesp.com.br/projeto/notebook`
> 
> **Problema:** Paths absolutos quebram entre ambientes e dependem de estrutura de usu√°rio espec√≠fico.
> 
> **Corre√ß√£o obrigat√≥ria:**
> ```yaml
> path: ../src/dlt/trusted/<pasta>/<arquivo>.ipynb
> ```
> 
> Use sempre paths relativos seguindo o padr√£o `../src/dlt/<camada>/<pasta>/<arquivo>.ipynb`.

---

### Para job sem webhook:

> üü° **MAJOR: Job sem notifica√ß√£o de falha**
> 
> **Problema:** Falhas no job n√£o ser√£o comunicadas √† equipe, dificultando resposta a incidentes.
> 
> **Corre√ß√£o sugerida:**
> ```yaml
> webhook_notifications:
>   on_failure:
>     - id: ${var.webhook_id}
> ```

---

### Para job sem queue:

> üü° **MAJOR: Job sem configura√ß√£o de fila**
> 
> **Problema:** Jobs sem queue configurada podem ter comportamento inconsistente de execu√ß√£o.
> 
> **Corre√ß√£o sugerida:**
> ```yaml
> queue:
>   enabled: true
> ```

---

### Para pipeline sem campos obrigat√≥rios:

> üü° **MAJOR: Pipeline sem configura√ß√£o de photon/serverless**
> 
> **Problema:** Campos `photon` e `serverless` devem estar explicitamente definidos.
> 
> **Corre√ß√£o sugerida:**
> ```yaml
> photon: true
> serverless: true
> allow_duplicate_names: true
> ```

---

### Para permiss√£o incorreta:

> üü° **MAJOR: Grupo de permiss√£o incorreto**
> 
> **Linha:** `group_name: "meu_grupo"`
> 
> **Problema:** O grupo padr√£o de permiss√£o deve ser `grp_engenharia_dados_db_basico`.
> 
> **Corre√ß√£o sugerida:**
> ```yaml
> permissions:
>   - group_name: "grp_engenharia_dados_db_basico"
>     level: "CAN_MANAGE_RUN"
> ```

---

### Para nomenclatura incorreta:

> üü° **MAJOR: Nome de arquivo fora do padr√£o**
> 
> **Arquivo:** `resources/pipeline_vendas.yml`
> 
> **Padr√£o esperado:** `resources/dlt_vendas.pipeline.yml`
> 
> **Motivo:** Nomenclatura padronizada facilita identifica√ß√£o e automa√ß√µes.

---

## Checklist de Revis√£o (ordem de prioridade)

1. **üî¥ SEGURAN√áA:** H√° segredos, tokens ou credenciais expostas?
2. **üü† HARDCODING:** Cat√°logos, schemas ou paths est√£o hardcoded?
3. **üü† YAML V√ÅLIDO:** O arquivo √© parse√°vel sem erros de sintaxe?
4. **üü° NOMENCLATURA:** Arquivos seguem padr√£o `dlt_*.pipeline.yml` ou `job_*.job.yml`?
5. **üü° ESTRUTURA JOB:** Tem schedule, tasks, webhook_notifications, queue, permissions?
6. **üü° ESTRUTURA PIPELINE:** Tem name, libraries, schema, catalog, photon, serverless, permissions?
7. **üü° VARI√ÅVEIS CORRETAS:** Cat√°logo usa `${var.catalog_<camada>}`? Webhook usa `${var.webhook_id}`?
8. **üü° PIPELINE_ID:** Tasks referenciam pipeline via `${resources.pipelines.pipeline_<nome>.id}`?
9. **üü° PATHS RELATIVOS:** Notebooks usam `../src/dlt/<camada>/...`?
10. **üü° GRUPO PERMISS√ÉO:** Usa `grp_engenharia_dados_db_basico`?
11. **üü¢ FORMATA√á√ÉO:** Indenta√ß√£o consistente (2 espa√ßos)?

---

## Anti-padr√µes (NUNCA sugerir)

O agente de review N√ÉO DEVE sugerir ou aprovar c√≥digo contendo:

| Anti-padr√£o | Motivo |
|-------------|--------|
| Paths absolutos (`/Workspace/...`, `/Repos/...`, `/Users/...`) | Quebra entre ambientes |
| Cat√°logos literais (`dev_lake`, `prd_lake`, `trusted`, `refined`) | Impede deploy automatizado |
| `catalog: ${var.catalog}` (sem sufixo de camada) | Deve usar `${var.catalog_<camada>}` |
| Segredos em texto claro | Viola√ß√£o de seguran√ßa |
| Jobs sem schedule | Execu√ß√£o manual n√£o rastre√°vel |
| Jobs sem webhook_notifications | Falhas silenciosas |
| Jobs sem queue | Comportamento de execu√ß√£o inconsistente |
| Pipelines sem photon/serverless definidos | Campos obrigat√≥rios |
| Pipelines trusted/refined sem DLT | Viola arquitetura de dados |
| Grupo de permiss√£o diferente de `grp_engenharia_dados_db_basico` | Fora do padr√£o de governan√ßa |
| `timezone_id` diferente de `UTC` | Padr√£o do cliente |
| YAML com sintaxe de GitHub Actions ou Azure Pipelines | Incompat√≠vel com Databricks |
| Indenta√ß√£o com tabs (usar 2 espa√ßos) | Padr√£o YAML |

---

## Valida√ß√£o T√©cnica

Antes de aprovar, verificar:

1. **YAML v√°lido:** Arquivo pode ser parseado sem erros
2. **Vari√°veis corretas:** 
   - Cat√°logo: `${var.catalog_raw}`, `${var.catalog_trusted}`, `${var.catalog_refined}`, `${var.catalog_stg}`
   - Webhook: `${var.webhook_id}`
   - Pipeline ID: `${resources.pipelines.pipeline_<nome>.id}`
3. **Paths existem:** Notebooks em `../src/dlt/<camada>/...` existem no reposit√≥rio
4. **Cron v√°lido:** Express√£o quartz √© v√°lida (ex: `0 0 6 * * ?` = 6h diariamente)
5. **Timezone:** Deve ser `UTC`
6. **Grupo de permiss√£o:** Deve ser `grp_engenharia_dados_db_basico`
7. **Campos de pipeline:** `photon`, `serverless`, `allow_duplicate_names` definidos
```
